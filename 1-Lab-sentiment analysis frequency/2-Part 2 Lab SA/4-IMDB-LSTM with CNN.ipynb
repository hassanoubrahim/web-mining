{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use \"IMDB movie review sentiment classification dataset\"\n",
    "\n",
    "Dataset Description: https://keras.io/api/datasets/imdb/\n",
    "\n",
    "This is a dataset of 25,000 movie reviews from IMDB, tagged by sentiment (positive/negative). The reviews have been preprocessed and each review is coded as a list of (whole) word indexes. For convenience, words are indexed by their overall frequency in the dataset, so that, for example, the integer \"3\" encodes the 3rd most frequent word in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:11.406641Z",
     "iopub.status.busy": "2023-06-18T13:21:11.405899Z",
     "iopub.status.idle": "2023-06-18T13:21:11.412660Z",
     "shell.execute_reply": "2023-06-18T13:21:11.410252Z",
     "shell.execute_reply.started": "2023-06-18T13:21:11.406605Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:11.414786Z",
     "iopub.status.busy": "2023-06-18T13:21:11.414342Z",
     "iopub.status.idle": "2023-06-18T13:21:11.421826Z",
     "shell.execute_reply": "2023-06-18T13:21:11.420695Z",
     "shell.execute_reply.started": "2023-06-18T13:21:11.414753Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:11.424589Z",
     "iopub.status.busy": "2023-06-18T13:21:11.424217Z",
     "iopub.status.idle": "2023-06-18T13:21:11.432707Z",
     "shell.execute_reply": "2023-06-18T13:21:11.431613Z",
     "shell.execute_reply.started": "2023-06-18T13:21:11.424558Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the embedding layer which defines the first hidden layer of the network. it must specify 3 arguments:\n",
    "\n",
    "input_dim: the size of the vocabulary in the text\n",
    "\n",
    "output_dim: this is the size of the vector space in which each word will be immersed\n",
    "\n",
    "input_legth: this is the size of the sequence, for example if your documents contain 100 words each then it is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 11:51:42.075881: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 11:51:44.297655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:44.299489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:44.301115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:44.548026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:44.550855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:44.553212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:45.557360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:45.559511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:51:45.561091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 11:53:36.598663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:53:36.600551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "\n",
      "2023-06-18 11:53:36.602172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 155s 384ms/step - loss: 0.4423 - accuracy: 0.7821 - val_loss: 0.3706 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 2/6\n",
      "\n",
      "391/391 [==============================] - 131s 336ms/step - loss: 0.2451 - accuracy: 0.9056 - val_loss: 0.2733 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 3/6\n",
      "\n",
      "391/391 [==============================] - 142s 364ms/step - loss: 0.1981 - accuracy: 0.9256 - val_loss: 0.3524 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 4/6\n",
      "\n",
      "391/391 [==============================] - 139s 355ms/step - loss: 0.1644 - accuracy: 0.9400 - val_loss: 0.3013 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 5/6\n",
      "\n",
      "391/391 [==============================] - 135s 345ms/step - loss: 0.1362 - accuracy: 0.9524 - val_loss: 0.3577 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 6/6\n",
      "\n",
      "391/391 [==============================] - 142s 363ms/step - loss: 0.1105 - accuracy: 0.9629 - val_loss: 0.3660 - val_accuracy: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0b077eaf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tyhe model \n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.99%\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a simple example of the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:23.975561Z",
     "iopub.status.busy": "2023-06-18T13:21:23.975208Z",
     "iopub.status.idle": "2023-06-18T13:21:23.980290Z",
     "shell.execute_reply": "2023-06-18T13:21:23.979363Z",
     "shell.execute_reply.started": "2023-06-18T13:21:23.975534Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "#docs = numpy.arange(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:24.821755Z",
     "iopub.status.busy": "2023-06-18T13:21:24.821059Z",
     "iopub.status.idle": "2023-06-18T13:21:24.826288Z",
     "shell.execute_reply": "2023-06-18T13:21:24.825319Z",
     "shell.execute_reply.started": "2023-06-18T13:21:24.821720Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = numpy.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:25.628750Z",
     "iopub.status.busy": "2023-06-18T13:21:25.628071Z",
     "iopub.status.idle": "2023-06-18T13:21:25.633702Z",
     "shell.execute_reply": "2023-06-18T13:21:25.632533Z",
     "shell.execute_reply.started": "2023-06-18T13:21:25.628714Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:26.165999Z",
     "iopub.status.busy": "2023-06-18T13:21:26.165655Z",
     "iopub.status.idle": "2023-06-18T13:21:26.170760Z",
     "shell.execute_reply": "2023-06-18T13:21:26.169800Z",
     "shell.execute_reply.started": "2023-06-18T13:21:26.165969Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:26.695613Z",
     "iopub.status.busy": "2023-06-18T13:21:26.695249Z",
     "iopub.status.idle": "2023-06-18T13:21:26.704382Z",
     "shell.execute_reply": "2023-06-18T13:21:26.703270Z",
     "shell.execute_reply.started": "2023-06-18T13:21:26.695585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 34],\n",
       " [42, 32],\n",
       " [28, 49],\n",
       " [33, 32],\n",
       " [30],\n",
       " [34],\n",
       " [45, 49],\n",
       " [47, 42],\n",
       " [45, 32],\n",
       " [21, 16, 34, 32]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:27.228175Z",
     "iopub.status.busy": "2023-06-18T13:21:27.227705Z",
     "iopub.status.idle": "2023-06-18T13:21:27.235239Z",
     "shell.execute_reply": "2023-06-18T13:21:27.234251Z",
     "shell.execute_reply.started": "2023-06-18T13:21:27.228135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 34  0  0]\n",
      " [42 32  0  0]\n",
      " [28 49  0  0]\n",
      " [33 32  0  0]\n",
      " [30  0  0  0]\n",
      " [34  0  0  0]\n",
      " [45 49  0  0]\n",
      " [47 42  0  0]\n",
      " [45 32  0  0]\n",
      " [21 16 34 32]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = sequence.pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define our Embedding layer as part of our model.\n",
    "\n",
    "The embedding has a vocabulary of 50 and an entry length of 4. We will choose a small embedding space of 8 dimensions.\n",
    "\n",
    "The model is a simple binary classification model. It is important to note that the output of the Embedding layer will be 4 vectors of 8 dimensions each, one for each word. We flatten it (the flatten layer) into a 32-element vector to pass it to the Dense output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:28.948410Z",
     "iopub.status.busy": "2023-06-18T13:21:28.947859Z",
     "iopub.status.idle": "2023-06-18T13:21:33.429895Z",
     "shell.execute_reply": "2023-06-18T13:21:33.428910Z",
     "shell.execute_reply.started": "2023-06-18T13:21:28.948377Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:54.988959Z",
     "iopub.status.busy": "2023-06-18T13:21:54.988098Z",
     "iopub.status.idle": "2023-06-18T13:21:55.010443Z",
     "shell.execute_reply": "2023-06-18T13:21:55.009653Z",
     "shell.execute_reply.started": "2023-06-18T13:21:54.988914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper (ModuleWrapp  (None, 4, 8)             400       \n",
      " er)                                                             \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWra  (None, 32)               0         \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:43.126123Z",
     "iopub.status.busy": "2023-06-18T13:21:43.125760Z",
     "iopub.status.idle": "2023-06-18T13:21:49.026453Z",
     "shell.execute_reply": "2023-06-18T13:21:49.025232Z",
     "shell.execute_reply.started": "2023-06-18T13:21:43.126094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79c2782cdc00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:21:49.028792Z",
     "iopub.status.busy": "2023-06-18T13:21:49.028350Z",
     "iopub.status.idle": "2023-06-18T13:21:49.223505Z",
     "shell.execute_reply": "2023-06-18T13:21:49.222543Z",
     "shell.execute_reply.started": "2023-06-18T13:21:49.028758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do: \n",
    "\n",
    "1. Try the same thing on Google reviews dataset ( the file is given in the lab directory)\n",
    "2. try to change the embedding representation using Glove and Skipgram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:23:02.401771Z",
     "iopub.status.busy": "2023-06-18T13:23:02.401397Z",
     "iopub.status.idle": "2023-06-18T13:23:02.655774Z",
     "shell.execute_reply": "2023-06-18T13:23:02.654618Z",
     "shell.execute_reply.started": "2023-06-18T13:23:02.401742Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "google_reviews = pd.read_csv('/kaggle/input/reviews/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:23:05.411600Z",
     "iopub.status.busy": "2023-06-18T13:23:05.411074Z",
     "iopub.status.idle": "2023-06-18T13:23:05.424973Z",
     "shell.execute_reply": "2023-06-18T13:23:05.423957Z",
     "shell.execute_reply.started": "2023-06-18T13:23:05.411560Z"
    }
   },
   "outputs": [],
   "source": [
    "df = google_reviews[['content', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:23:05.994964Z",
     "iopub.status.busy": "2023-06-18T13:23:05.994399Z",
     "iopub.status.idle": "2023-06-18T13:23:07.702445Z",
     "shell.execute_reply": "2023-06-18T13:23:07.701412Z",
     "shell.execute_reply.started": "2023-06-18T13:23:05.994926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max(len(content.split()) for content in df[\"content\"])\n",
    "\n",
    "# Tokenize the content\n",
    "num_words=500\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(df[\"content\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"content\"])\n",
    "\n",
    "# Pad sequences to the same length\n",
    "content_embeddings = sequence.pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(content_embeddings, df['score'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:36:43.260180Z",
     "iopub.status.busy": "2023-06-18T13:36:43.259819Z",
     "iopub.status.idle": "2023-06-18T13:36:43.585259Z",
     "shell.execute_reply": "2023-06-18T13:36:43.584137Z",
     "shell.execute_reply.started": "2023-06-18T13:36:43.260150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 391, 32)           16000     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 391, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 195, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               82432     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "sequence_length = X_train.shape[1]  # Assuming X_train is a numpy array\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_vecor_length, input_length=sequence_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:36:43.838396Z",
     "iopub.status.busy": "2023-06-18T13:36:43.838057Z",
     "iopub.status.idle": "2023-06-18T13:36:48.666326Z",
     "shell.execute_reply": "2023-06-18T13:36:48.665151Z",
     "shell.execute_reply.started": "2023-06-18T13:36:43.838367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7243567109107971\n",
      "Test Accuracy: 0.02190476283431053\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:28:27.852223Z",
     "iopub.status.busy": "2023-06-18T13:28:27.851845Z",
     "iopub.status.idle": "2023-06-18T13:28:39.665860Z",
     "shell.execute_reply": "2023-06-18T13:28:39.664751Z",
     "shell.execute_reply.started": "2023-06-18T13:28:27.852174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the GloVe embeddings\n",
    "glove_embeddings = {}  # Dictionary to store the embeddings\n",
    "with open('/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = numpy.array(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:29:55.352217Z",
     "iopub.status.busy": "2023-06-18T13:29:55.351339Z",
     "iopub.status.idle": "2023-06-18T13:29:55.363393Z",
     "shell.execute_reply": "2023-06-18T13:29:55.362431Z",
     "shell.execute_reply.started": "2023-06-18T13:29:55.352152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "embedding_matrix = numpy.zeros((num_words, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index < num_words:\n",
    "        embedding_vector = glove_embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:33:30.790243Z",
     "iopub.status.busy": "2023-06-18T13:33:30.789465Z",
     "iopub.status.idle": "2023-06-18T13:33:30.797955Z",
     "shell.execute_reply": "2023-06-18T13:33:30.796933Z",
     "shell.execute_reply.started": "2023-06-18T13:33:30.790175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:34:33.847793Z",
     "iopub.status.busy": "2023-06-18T13:34:33.847431Z",
     "iopub.status.idle": "2023-06-18T13:34:34.165301Z",
     "shell.execute_reply": "2023-06-18T13:34:34.164547Z",
     "shell.execute_reply.started": "2023-06-18T13:34:33.847763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 100)         50000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 50,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the Embedding layer\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "embedding_dim = embedding_matrix.shape[1]\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
    "\n",
    "# Add other layers to the model\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:35:53.761524Z",
     "iopub.status.busy": "2023-06-18T13:35:53.761135Z",
     "iopub.status.idle": "2023-06-18T13:35:57.430611Z",
     "shell.execute_reply": "2023-06-18T13:35:57.429505Z",
     "shell.execute_reply.started": "2023-06-18T13:35:53.761495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9715513586997986\n",
      "Test Accuracy: 0.030793650075793266\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
